{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read files from ETL notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext jupyternotify\n",
    "%store -r item_cat\n",
    "%store -r item\n",
    "%store -r sub\n",
    "%store -r shops\n",
    "%store -r sales_test\n",
    "%store -r sales_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "\n",
    "import warnings\n",
    "\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from plotly import graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "\n",
    "# Initialize plotly\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "from time import time\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "\n",
    "\n",
    "# SKLEARN\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit, KFold\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# TSFRESH\n",
    "from tsfresh.feature_extraction import ComprehensiveFCParameters, extract_features, MinimalFCParameters, EfficientFCParameters\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh import extract_relevant_features\n",
    "\n",
    "# LightGBM\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Sklearn-pandas\n",
    "from sklearn_pandas import CategoricalImputer, FunctionTransformer, DataFrameMapper\n",
    "\n",
    "# Bayessian Optimization\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# vecstack\n",
    "from vecstack import stacking\n",
    "\n",
    "# Transformers\n",
    "from features_transformers import DateFeatureExtractor, TSFreshTransformer\n",
    "from split_dataset import split_dataset, split_and_transform\n",
    "\n",
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "class TSFreshTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, column_id, column_sort, column_value, extraction_settings):\n",
    "        self.column_id = column_id\n",
    "        self.column_sort = column_sort\n",
    "        self.column_value = column_value\n",
    "        self.extraction_settings = extraction_settings\n",
    "    \n",
    "    def fit(self, train_x, train_y=None, **fit_params):\n",
    "        return self\n",
    "   \n",
    "    def transform(self, X_train, y_train=None, **fit_params):\n",
    "\n",
    "        X_features = extract_features(\n",
    "            X_train,\n",
    "            column_id=self.column_id, \n",
    "            column_sort=self.column_sort, \n",
    "            column_value=self.column_value, \n",
    "            default_fc_parameters=self.extraction_settings)\n",
    "        \n",
    "        impute(X_features)\n",
    "        return X_features \n",
    "    \n",
    "    def get_params(self):\n",
    "         return {'column_id': self.column_id, \n",
    "                'column_sort': self.column_sort,\n",
    "                'column_value': self.column_value,\n",
    "                'extraction_settings': self.extraction_settings}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "    \n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        return self.fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table denormalization and joining tables. Then was created features:\n",
    "- key = combined_key. item_id + shop_id\n",
    "- is_actual = current item is actual in shop\n",
    "- item_price_{number} - item price category (created by KMeans)\n",
    "- months_period_of_product - life period of item\n",
    "- item_price_{statistic} - item_price statistics\n",
    "- date_block_num_{statistic} - date_block_num statistics\n",
    "- item_cnt_day - month sum of sold items\n",
    "- returned_items_{statistic} count of returned items \n",
    "- pca_{number}_{month}_{statistic + ts features} - time series features which derived from item_cnt_day by each period of months. PCA used for dimensionaility reduction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Cell magic `%%notify` not found.\n"
     ]
    }
   ],
   "source": [
    "%%notify\n",
    "df = sales_train.reset_index().copy()\n",
    "# sales train + item\n",
    "df_cat_id = df.set_index('item_id').join(item[['item_id', 'item_category_id']].set_index('item_id'), how='left').reset_index()\n",
    "\n",
    "df_gf = DateFeatureExtractor('date').fit_transform(df_cat_id)\n",
    "df_cleaned = df_gf\\\n",
    ".groupby(['shop_id', 'item_id', 'date_block_num', 'month', 'year', 'item_category_id'], as_index=False)\\\n",
    ".agg({'item_price':'median', 'item_cnt_day':'sum'})\n",
    "\n",
    "df_cleaned['key'] = df_cleaned.progress_apply(lambda x: str(int(x['shop_id'])) + \"_\" + str(int(x['item_id'])), axis=1)\n",
    "df_cleaned['key'] = LabelEncoder().fit_transform(df_cleaned['key'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Product is actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_items_id = df_cleaned[df_cleaned['date_block_num'] == df_cleaned['date_block_num'].max()]['item_id']\n",
    "actual_items_id = np.isin(df_cleaned['item_id'], actual_items_id)\n",
    "df_cleaned['is_actual'] = np.where(actual_items_id, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "item_price_{number} - item price category (created by KMeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_name_for_item_price_clust(col_name=\"item_price \"):\n",
    "    CLUSTERS_COUNT = 6\n",
    "    return list(map(lambda x: col_name + str(x), range(0, CLUSTERS_COUNT)))\n",
    "\n",
    "\n",
    "df_cleaned['median_item_price'] = df_cleaned[['key', 'item_price']].groupby('key').transform('median')\n",
    "it = df_cleaned['median_item_price'].values.reshape(-1, 1)\n",
    "\n",
    "kmeans = KMeans(6)\n",
    "kmeans.fit(it)\n",
    "\n",
    "clusters = kmeans.predict(it)\n",
    "ohe_clusters = pd.get_dummies(clusters)\n",
    "ohe_clusters.columns = generate_name_for_item_price_clust()\n",
    "df_cleaned = pd.concat([df_cleaned, ohe_clusters], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features_from_train_set(X_train, X_test, key=['key']):\n",
    "    global ad\n",
    "    def min_max_transformation(df, col):\n",
    "        assert len(df) != 0\n",
    "        assert col != \"\"       \n",
    "        features = df[[*key, col]]\\\n",
    "             .groupby(key, as_index=False)\\\n",
    "             .agg(['max', 'min', 'std', 'mean', 'median'])\n",
    "        \n",
    "        features.columns = [\"_\".join(x) for x in features.columns.ravel()]\n",
    "        return features\n",
    "        \n",
    "    def merge_train_test(train_df, test_df, result):\n",
    "        train_df = train_df.merge(result, on=key, right_index=False, how='left')\n",
    "        test_df = test_df.merge(result, on=key, right_index=False, how='left')\n",
    "        return train_df, test_df\n",
    "\n",
    "    ## Features\n",
    "        \n",
    "    x_item_price = min_max_transformation(X_train, 'item_price')\n",
    "    x_date_block_num = min_max_transformation(X_train, 'date_block_num')\n",
    "\n",
    "    months_period_of_product = X_train[['key', 'date_block_num']]\\\n",
    "                               .groupby('key')\\\n",
    "                               .progress_apply(lambda x: x['date_block_num'].max() - x['date_block_num'].min())\\\n",
    "                               .to_frame()\\\n",
    "                               .reset_index()\n",
    "    \n",
    "    months_period_of_product.columns = ['key', 'months_period_of_product']\n",
    "\n",
    "    for i, tr in enumerate([x_item_price, months_period_of_product, x_date_block_num]):\n",
    "        X_train, X_test = merge_train_test(X_train, X_test, tr)\n",
    "        print(X_train.shape)\n",
    "\n",
    "    X_train = X_train.fillna(0)\n",
    "    X_test = X_test.fillna(0)\n",
    "    \n",
    "    return X_train, X_test\n",
    "\n",
    "def split_dataset(gb_df, date_col, pred_col, prediction_size = 5):\n",
    "    gb_df = gb_df.copy().sort_values(by=[date_col])\n",
    "    gb_df = gb_df.dropna()\n",
    "    X = gb_df.drop(pred_col, axis=1)\n",
    "    y = gb_df[pred_col]\n",
    "    \n",
    "    max_month = X[date_col].max()\n",
    "    \n",
    "    train_val_condition = X[date_col] < (max_month - prediction_size)\n",
    "    test_condition = X[date_col] >= (max_month - prediction_size)\n",
    "    \n",
    "    X_train_val = X[train_val_condition].reset_index(drop=True)\n",
    "    X_test = X[test_condition].reset_index(drop=True)\n",
    "    y_train_val = y[train_val_condition].reset_index(drop=True)\n",
    "    y_test = y[test_condition].reset_index(drop=True)\n",
    "    \n",
    "    return X_train_val, y_train_val, X_test, y_test\n",
    "\n",
    "def split_and_transform(df, **kwargs):\n",
    "  ## Add transformers \n",
    "    X_train_val, y_train_val, X_test, y_test = split_dataset(df, **kwargs)\n",
    "    print(X_train_val.shape)\n",
    "    X_train_val, X_test = generate_features_from_train_set(X_train_val, X_test)    \n",
    "    print(X_train_val.shape)\n",
    "    return X_train_val, y_train_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>key</th>\n",
       "      <th>is_actual</th>\n",
       "      <th>median_item_price</th>\n",
       "      <th>...</th>\n",
       "      <th>item_price 2</th>\n",
       "      <th>item_price 3</th>\n",
       "      <th>item_price 4</th>\n",
       "      <th>item_price 5</th>\n",
       "      <th>item_price_max</th>\n",
       "      <th>item_price_min</th>\n",
       "      <th>item_price_std</th>\n",
       "      <th>item_price_mean</th>\n",
       "      <th>item_price_median</th>\n",
       "      <th>months_period_of_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>4885</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>716.0</td>\n",
       "      <td>8163</td>\n",
       "      <td>1</td>\n",
       "      <td>808.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1165.339966</td>\n",
       "      <td>716.0</td>\n",
       "      <td>144.775803</td>\n",
       "      <td>823.758179</td>\n",
       "      <td>716.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>3533</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>999.0</td>\n",
       "      <td>94453</td>\n",
       "      <td>0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>3527</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>199.0</td>\n",
       "      <td>94451</td>\n",
       "      <td>0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>199.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>199.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>3470</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>349.0</td>\n",
       "      <td>94450</td>\n",
       "      <td>0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>349.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>349.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>3470</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>349.0</td>\n",
       "      <td>94450</td>\n",
       "      <td>0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>349.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>349.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   shop_id  item_id  date_block_num  month  year  item_category_id  \\\n",
       "0       10     4885               0      1     0                23   \n",
       "1       23     3533               0      1     0                30   \n",
       "2       23     3527               0      1     0                77   \n",
       "3       23     3470               0      3     0                30   \n",
       "4       23     3470               0      1     0                30   \n",
       "\n",
       "   item_price    key  is_actual  median_item_price            ...             \\\n",
       "0       716.0   8163          1              808.0            ...              \n",
       "1       999.0  94453          0              999.0            ...              \n",
       "2       199.0  94451          0              199.0            ...              \n",
       "3       349.0  94450          0              349.0            ...              \n",
       "4       349.0  94450          0              349.0            ...              \n",
       "\n",
       "   item_price 2  item_price 3  item_price 4  item_price 5  item_price_max  \\\n",
       "0             0             0             0             0     1165.339966   \n",
       "1             0             0             0             0      999.000000   \n",
       "2             1             0             0             0      199.000000   \n",
       "3             1             0             0             0      349.000000   \n",
       "4             1             0             0             0      349.000000   \n",
       "\n",
       "   item_price_min  item_price_std  item_price_mean  item_price_median  \\\n",
       "0           716.0      144.775803       823.758179              716.0   \n",
       "1           999.0        0.000000       999.000000              999.0   \n",
       "2           199.0        0.000000       199.000000              199.0   \n",
       "3           349.0        0.000000       349.000000              349.0   \n",
       "4           349.0        0.000000       349.000000              349.0   \n",
       "\n",
       "   months_period_of_product  \n",
       "0                      22.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ///// CODE TO TEST FEATURE ENGINEERING FEATURES\n",
    "\n",
    "# first_ten_products = df_cleaned[df_cleaned['key'] == 303844]\n",
    "# #full = df_cleaned[np.isin(df_cleaned['key'], first_ten_products)]\n",
    "# X_train_val, y_train_val, X_test, y_test = split_and_transform(first_ten_products, date_col='date_block_num',\\\n",
    "#                                                               pred_col='item_cnt_day', prediction_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%notify\n",
    "X_train_val, y_train_val, X_test, y_test = split_and_transform(df_cleaned, date_col='date_block_num',\\\n",
    "                                                              pred_col='item_cnt_day', prediction_size=1)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ts_features(df, X_train, X_test, it, month_threshold):\n",
    "    def merge(df, features, it):\n",
    "        return df.merge(features, how='left', left_on='key', right_on='id', right_index=False, suffixes=('', f'_{str(it)}'))\n",
    "    \n",
    "    def reduce_dimensions(features, month_threshold):\n",
    "        n_components=3\n",
    "        pca = PCA(n_components=n_components)\n",
    "        pca_features = pca.fit_transform(features)\n",
    "\n",
    "        print(f\"Explained variance {pca.explained_variance_ratio_}\")  \n",
    "\n",
    "        column_names = list(map(lambda x: f\"pca_{x}_{month_threshold}\", range(0, n_components)))\n",
    "        pca_df = pd.DataFrame(pca_features, columns = column_names).reset_index(drop=True)\n",
    "        features = pd.concat([features.reset_index()['id'], pca_df], axis=1)\n",
    "        return features\n",
    "    \n",
    "    df_more_than_0 = df[(df['months_period_of_product'] + 1) >= month_threshold]\n",
    "    \n",
    "    if df_more_than_0.shape[0] == 0:\n",
    "        return X_train, X_test\n",
    "  \n",
    "    print(\"item_cnt_day\")\n",
    "    features = TSFreshTransformer('key', 'date_block_num', 'item_cnt_day', EfficientFCParameters())\\\n",
    "        .fit_transform(df_more_than_0, axis=0)\n",
    "   \n",
    "    features = reduce_dimensions(features, month_threshold)\n",
    "\n",
    "    X_train = merge(X_train, features, it)\n",
    "    X_test = merge(X_test, features, it)\n",
    "    \n",
    "    print(\"returned_items\")\n",
    "    # return products tsfresh\n",
    "    returned_items = df_more_than_0['item_cnt_day'].apply(lambda x: x if x < 0 else 0).to_frame()\n",
    "    returned_items.columns = ['returned_items']        \n",
    "\n",
    "    pred_ts_data = pd.concat([df_more_than_0.reset_index(), returned_items.reset_index()], axis=1)\n",
    "\n",
    "    features = TSFreshTransformer('key', 'date_block_num', 'returned_items', MinimalFCParameters())\\\n",
    "    .fit_transform(pred_ts_data, axis=0)\n",
    "    \n",
    "    features = reduce_dimensions(features, month_threshold)\n",
    "        \n",
    "    X_train = merge(X_train, features, it)\n",
    "    X_test = merge(X_test, features, it)\n",
    "    \n",
    "    return X_train, X_test    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ts(X_train_val, y_train_val, X_test):\n",
    "    \n",
    "    assert X_train_val.shape[0] > X_test.shape[0]\n",
    "    assert X_train_val.shape[0] == y_train_val.shape[0]\n",
    "    \n",
    "    X_train_val_func = X_train_val.copy()\n",
    "    X_test_func = X_test.copy()\n",
    "\n",
    "    X = pd.concat([X_train_val.reset_index(), y_train_val.reset_index()], axis=1)\n",
    "\n",
    "    for i, month in tqdm(enumerate([12, 24])):\n",
    "        X_train_val_func, X_test_func = generate_ts_features(X, X_train_val_func, X_test_func, month, month)\n",
    "        \n",
    "    X_train_val_func = X_train_val_func.fillna(0)\n",
    "    X_test_func = X_test_func.fillna(0)\n",
    "  \n",
    "    return X_train_val_func, X_test_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "returned_items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:  10%|█         | 1/10 [14:46<2:12:57, 886.37s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:  20%|██        | 2/10 [15:16<1:23:55, 629.38s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:  30%|███       | 3/10 [28:02<1:18:13, 670.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:  40%|████      | 4/10 [28:49<48:20, 483.50s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:  50%|█████     | 5/10 [41:56<47:52, 574.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:  60%|██████    | 6/10 [42:53<27:56, 419.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:  70%|███████   | 7/10 [53:56<24:36, 492.24s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:  80%|████████  | 8/10 [54:59<12:07, 363.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:  90%|█████████ | 9/10 [1:07:53<08:06, 486.65s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction: 100%|██████████| 10/10 [1:08:52<00:00, 358.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance [9.99999810e-01 1.89930168e-07 3.92175999e-22]\n",
      "returned_items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:  10%|█         | 1/10 [00:03<00:30,  3.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:  20%|██        | 2/10 [00:04<00:22,  2.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:  30%|███       | 3/10 [00:05<00:15,  2.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:  40%|████      | 4/10 [00:07<00:11,  1.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:  50%|█████     | 5/10 [00:08<00:09,  1.88s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:  60%|██████    | 6/10 [00:10<00:07,  2.00s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:  70%|███████   | 7/10 [00:12<00:05,  1.94s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:  80%|████████  | 8/10 [00:14<00:03,  1.84s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:  90%|█████████ | 9/10 [00:15<00:01,  1.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction: 100%|██████████| 10/10 [00:16<00:00,  1.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance [9.99745621e-01 2.49204164e-04 2.94584582e-06]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1it [1:50:23, 6623.81s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "returned_items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:  10%|█         | 1/10 [02:35<23:15, 155.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:  20%|██        | 2/10 [02:39<14:40, 110.02s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:  30%|███       | 3/10 [05:26<14:48, 126.88s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:  40%|████      | 4/10 [05:37<09:13, 92.17s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:  50%|█████     | 5/10 [08:24<09:32, 114.59s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:  60%|██████    | 6/10 [08:27<05:24, 81.03s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:  70%|███████   | 7/10 [11:05<05:13, 104.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:  80%|████████  | 8/10 [11:13<02:30, 75.38s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:  90%|█████████ | 9/10 [13:57<01:42, 102.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction: 100%|██████████| 10/10 [13:59<00:00, 72.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance [1.00000000e+00 2.59181987e-21 2.02406738e-21]\n",
      "returned_items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:  10%|█         | 1/10 [00:00<00:08,  1.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:  30%|███       | 3/10 [00:02<00:06,  1.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:  40%|████      | 4/10 [00:02<00:04,  1.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:  50%|█████     | 5/10 [00:03<00:03,  1.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:  60%|██████    | 6/10 [00:03<00:02,  1.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:  70%|███████   | 7/10 [00:03<00:01,  1.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:  80%|████████  | 8/10 [00:04<00:00,  2.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction:  90%|█████████ | 9/10 [00:04<00:00,  2.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Feature Extraction: 100%|██████████| 10/10 [00:04<00:00,  2.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance [9.99818392e-01 1.79126054e-04 1.50188990e-06]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2it [2:07:01, 4935.92s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "#%%notify\n",
    "X_train_test, X_test_test = generate_ts(X_train_val, y_train_val, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_types(df):\n",
    "    for i in df.columns:\n",
    "        df[i] = df[i].astype('float32')    \n",
    "   \n",
    "    df['shop_id'] = df['shop_id'].astype('int32')\n",
    "    df['item_id'] = df['item_id'].astype('int32')\n",
    "    df['key'] = df['key'].astype('int32')\n",
    "    \n",
    "    df['is_actual'] = df['is_actual'].astype('int32')\n",
    "    df['months_period_of_product'] = df['months_period_of_product'].astype('int32')\n",
    "    \n",
    "    for col in generate_name_for_item_price_clust():\n",
    "        df[col] = df[col].astype('int32')\n",
    "    \n",
    "    drop_cols = df.columns[list(map(lambda x: x.startswith(\"id\"), df.columns))].values\n",
    "    df = df.drop(drop_cols, axis=1)\n",
    "    \n",
    "    date_block_nums = df.columns[list(map(lambda x: x.startswith(\"date_block_num\"), df.columns))].values\n",
    "\n",
    "    for col in date_block_nums:\n",
    "        df[col] = df[col].astype('int32')\n",
    "    \n",
    "    return df\n",
    "\n",
    "X_train_test = change_types(X_train_test)\n",
    "X_test_test = change_types(X_test_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = X_train_test.columns[list(map(lambda x: x.startswith(\"id\"), X_train_test.columns))].values\n",
    "X_train_test = X_train_test.drop(drop_cols, axis=1)\n",
    "X_test_test = X_test_test.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val = X_train_test\n",
    "X_test = X_test_test\n",
    "y_train_val = y_train_val\n",
    "y_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'X_train_val' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train_val' (Series)\n",
      "Stored 'y_test' (Series)\n"
     ]
    }
   ],
   "source": [
    "%store X_train_val\n",
    "%store X_test\n",
    "%store y_train_val\n",
    "%store y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val.to_pickle('X_train_val.pickle')\n",
    "y_train_val.to_pickle('y_train_val.pickle')\n",
    "\n",
    "X_test.to_pickle('X_test.pickle')\n",
    "y_test.to_pickle('y_test.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['shop_id', 'item_id', 'date_block_num', 'month', 'year',\n",
       "       'item_category_id', 'item_price', 'key', 'is_actual',\n",
       "       'median_item_price', 'item_price 0', 'item_price 1', 'item_price 2',\n",
       "       'item_price 3', 'item_price 4', 'item_price 5', 'item_price_max',\n",
       "       'item_price_min', 'item_price_std', 'item_price_mean',\n",
       "       'item_price_median', 'months_period_of_product', 'date_block_num_max',\n",
       "       'date_block_num_min', 'date_block_num_std', 'date_block_num_mean',\n",
       "       'date_block_num_median', 'pca_0_12', 'pca_1_12', 'pca_2_12',\n",
       "       'pca_0_12_12', 'pca_1_12_12', 'pca_2_12_12', 'pca_0_24', 'pca_1_24',\n",
       "       'pca_2_24', 'pca_0_24_24', 'pca_1_24_24', 'pca_2_24_24'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_val.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
